{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomontessema/Generative-AI-with-Python/blob/main/notebooks/Vector_Databases_with_Pinecone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone"
      ],
      "metadata": {
        "id": "olnA_XDNblpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vec2text"
      ],
      "metadata": {
        "id": "DJsZA0xyislo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2LsoQruewpq"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pinecone\n",
        "import openai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "load_dotenv()\n",
        "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Create Pinecone client\n",
        "pc = Pinecone(api_key=api_key)\n",
        "\n",
        "# Create index if it doesn't exist\n",
        "if \"my-index\" not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=\"my-index\",\n",
        "        dimension=1536,  # Match your embedding model output\n",
        "        metric=\"cosine\",  # Or 'euclidean', 'dotproduct'\n",
        "        spec=ServerlessSpec(\n",
        "            cloud=\"aws\",  # Or 'gcp'\n",
        "            region=\"us-east-1\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "# Connect to index\n",
        "index = pc.Index(\"my-index\")\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Embed text using OpenAI\n",
        "def embed(text):\n",
        "    response = client.embeddings.create(\n",
        "        input=[text],\n",
        "        model=\"text-embedding-ada-002\"\n",
        "    )\n",
        "    return response.data[0].embedding\n",
        "\n",
        "# Upsert vector\n",
        "index.upsert([\n",
        "    (\"concept1\", embed(\"The theory of relativity and its implications\"), {\"topic\": \"physics\"}),\n",
        "    (\"concept2\", embed(\"The role of empathy in leadership\"), {\"topic\": \"psychology\"})\n",
        "])\n",
        "\n",
        "# Query\n",
        "query_vector = embed(\"My cat is so cute\")\n",
        "results = index.query(vector=query_vector, top_k=5, include_metadata=True)\n",
        "results\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_vector = embed(\"The theory of relativity\")\n",
        "results = index.query(\n",
        "    vector=query_vector,\n",
        "    top_k=5,\n",
        "    include_metadata=True,\n",
        "    filter={\"topic\": \"physics\"}  # Only return vectors tagged with topic 'physics'\n",
        ")\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "W8tpVR3WiXwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updating an existing vector by ID\n",
        "index.upsert([\n",
        "    (\"concept1\", embed(\"Updated theory of relativity and its modern implications\"), {\"topic\": \"physics\"})\n",
        "])\n",
        "\n",
        "# Deleting a vector by ID\n",
        "index.delete(ids=[\"concept2\"])\n",
        "\n",
        "all_vectors = index.query(\n",
        "    vector=embed(\"The theory of relativity\"),  # Use a relevant query string here\n",
        "    top_k=10,\n",
        "    include_metadata=True\n",
        ")\n",
        "print(all_vectors)\n"
      ],
      "metadata": {
        "id": "9K1AT7il2Mi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Upserts and Queries Explore how to efficiently upsert and query large batches of vectors, which is essential for scaling your application.\n",
        "\n",
        "Handling Different Similarity Metrics Experiment with different similarity metrics (cosine, euclidean, dotproduct) and understand how they affect search results.\n",
        "\n",
        "Integrating Pinecone with Applications Build simple applications or APIs that use Pinecone for semantic search or recommendations, combining it with OpenAI for embedding generation.\n",
        "\n",
        "Performance and Cost Optimization Learn best practices for index dimension sizing, vector pruning, and query tuning to optimize speed and cost."
      ],
      "metadata": {
        "id": "aFLa6uxM3asg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch upsert example\n",
        "texts = [\n",
        "    \"Quantum mechanics and its applications\",\n",
        "    \"The psychology of motivation\",\n",
        "    \"Advances in renewable energy technology\"\n",
        "]\n",
        "\n",
        "vectors_to_upsert = []\n",
        "for i, text in enumerate(texts, start=3):\n",
        "    vectors_to_upsert.append((f\"concept{i}\", embed(text), {\"topic\": \"mixed\"}))\n",
        "\n",
        "index.upsert(vectors_to_upsert)\n",
        "\n",
        "# Query after batch upsert\n",
        "query_vector = embed(\"renewable energy\")\n",
        "results = index.query(\n",
        "    vector=query_vector,\n",
        "    top_k=5,\n",
        "    include_metadata=True\n",
        ")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "-9SbD74s3YM0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}